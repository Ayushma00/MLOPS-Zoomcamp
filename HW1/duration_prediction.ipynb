{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Taxi Trip Duration Prediction\n",
    "\n",
    "This notebook demonstrates the process of predicting taxi trip durations using linear regression. The data is sourced from NYC taxi trips, and we perform the following steps:\n",
    "\n",
    "1. Import necessary libraries\n",
    "2. Load and preprocess the January dataset\n",
    "3. Feature extraction and transformation\n",
    "4. Train a linear regression model\n",
    "5. Validate the model on February data\n",
    "\n",
    "## Import Libraries\n",
    "\n",
    "We begin by importing the necessary libraries for data manipulation, visualization, and machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load January Data\n",
    "\n",
    "Next, we load the January data and examine its structure. We also compute the trip duration for each trip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current path: d:\\mLOPS\\2024-MLOPS-ZOOMCAMP\\HW1\n"
     ]
    }
   ],
   "source": [
    "current_path = Path.cwd()\n",
    "print(f\"Current path: {current_path}\")\n",
    "data_path = current_path / \"Data\\yellow_tripdata_2023-01.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total columns in January datasets : 19\n"
     ]
    }
   ],
   "source": [
    "df_jan = pd.read_parquet(data_path)\n",
    "print(\"The total columns in January datasets :\",len(df_jan.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Trip Duration\n",
    "\n",
    "We calculate the trip duration in minutes and filter out trips that are either too short or too long (outside 1 to 60 minutes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jan[\"duration_datetime\"] = df_jan[\"tpep_dropoff_datetime\"] - df_jan[\"tpep_pickup_datetime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jan['trip_duration_minutes'] = df_jan['duration_datetime'].dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Trip Durations (in minutes): 42.59\n"
     ]
    }
   ],
   "source": [
    "trip_duration_std = df_jan['trip_duration_minutes'].std()\n",
    "print(f\"Standard Deviation of Trip Durations (in minutes): {trip_duration_std:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df_jan[(df_jan[\"trip_duration_minutes\"]>=1) & (df_jan[\"trip_duration_minutes\"]<=60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of records left after dropping outliers: 98.12%\n"
     ]
    }
   ],
   "source": [
    "fraction_left = len(filtered_df) / len(df_jan)\n",
    "\n",
    "# Display the fraction\n",
    "print(f\"Fraction of records left after dropping outliers: {fraction_left:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'congestion_surcharge', 'airport_fee',\n",
       "       'duration_datetime', 'trip_duration_minutes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "We extract relevant features for the model, specifically the pickup and dropoff location IDs. These are then transformed using a `DictVectorizer`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =filtered_df[['PULocationID', 'DOLocationID']]\n",
    "features = features.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dicts = features.to_dict(orient='records')\n",
    "\n",
    "# Fit a DictVectorizer\n",
    "dict_vectorizer = DictVectorizer()\n",
    "feature_matrix=dict_vectorizer.fit_transform(data_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensionality of this matrix (number of columns) :  515\n"
     ]
    }
   ],
   "source": [
    "print(\"The dimensionality of this matrix (number of columns) : \",feature_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = filtered_df['trip_duration_minutes'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Linear Regression Model\n",
    "\n",
    "We train a linear regression model on the transformed feature matrix and the target variable (trip duration).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(feature_matrix, target)\n",
    "\n",
    "# Predict target variable on the training data\n",
    "predictions = model.predict(feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance on Training Data\n",
    "\n",
    "We evaluate the model's performance on the training data by calculating the Mean Squared Error (MSE) and Root Mean Squared Error (RMSE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on the training data: 58.51\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate RMSE\n",
    "mse = mean_squared_error(target, predictions)\n",
    "\n",
    "# Display the RMSE\n",
    "print(f\"Mean Squared Error (MSE) on the training data: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on the training data: 7.65\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error (RMSE) on the training data: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation on February Data\n",
    "\n",
    "We validate the model on February data by repeating the preprocessing and feature extraction steps, then predicting trip durations and calculating the RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df):\n",
    "    df[\"duration_datetime\"] = df[\"tpep_dropoff_datetime\"] - df[\"tpep_pickup_datetime\"]\n",
    "    df['trip_duration_minutes'] = df['duration_datetime'].dt.total_seconds() / 60\n",
    "    filtered_df = df[(df[\"trip_duration_minutes\"]>=1) & (df[\"trip_duration_minutes\"]<=60)]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extraction(df):\n",
    "    features =df[['PULocationID', 'DOLocationID']]\n",
    "    features = features.astype('str')\n",
    "    data_dicts = features.to_dict(orient='records')\n",
    "    feature_matrix=dict_vectorizer.transform(data_dicts)\n",
    "    target = df['trip_duration_minutes'].values\n",
    "    return feature_matrix, target\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = current_path / \"Data\\yellow_tripdata_2023-02.parquet\"\n",
    "df_val = pd.read_parquet(data_path)\n",
    "df_val_filtered = data_preprocessing(df_val)\n",
    "X_test,y_test = features_extraction(df_val_filtered)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2855951, 515)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on the validation data: 7.81\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"Root Mean Squared Error (RMSE) on the validation data: {rmse:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
